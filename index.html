from fastapi import FastAPI
from pydantic import BaseModel
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import MultinomialNB

# Criando a API
app = FastAPI(title="IA via HTTP")

# Dados de treino
textos = [
    "eu gostei muito",
    "isso é incrível",
    "amei o produto",
    "odiei isso",
    "péssima experiência",
    "não gostei"
]

labels = ["positivo", "positivo", "positivo", "negativo", "negativo", "negativo"]

# Treinando a IA
vectorizer = CountVectorizer()
X = vectorizer.fit_transform(textos)

model = MultinomialNB()
model.fit(X, labels)

# Modelo de entrada
class TextoEntrada(BaseModel):
    texto: str

# Endpoint HTTP
@app.post("/analisar")
def analisar_sentimento(dados: TextoEntrada):
    texto_vec = vectorizer.transform([dados.texto])
    resultado = model.predict(texto_vec)[0]

    return {
        "texto": dados.texto,
        "sentimento": resultado
    }
